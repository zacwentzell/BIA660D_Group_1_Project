{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recommendation System for Hoboken Reviews(yelp)\n",
    "### - Methodlogy: Basic method(3)+ Machine learning methods(5)\n",
    "### - Objective: providing 3 more restaurants for each customers based on historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py2.7\n",
    "#import graphlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py3.6\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#%%python\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data EDA and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Hoboken_restaurants_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "del df['Unnamed: 0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.restaurant_price.isnull() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only some price value is missing since these value is not exist on the Yelp. So I will just remain them as NA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data definition:\n",
    "- user_id: Unique id for each customer\n",
    "- user_name: customer's name\n",
    "- user_raing: original rating for one restaurant per time\n",
    "- user_text: customer's review for one restaurant per time\n",
    "- restaurant_name: unique name for each restaurant\n",
    "- restaurant_price: degree of cheap or expensive of one restaurant\n",
    "- restaurant_type: the style and theme of one restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data processing one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = pd.DataFrame(df.user_id.value_counts().head(10))\n",
    "user_id.reset_index(level=0, inplace = True)\n",
    "user_id.columns = ['user_id', 'count']\n",
    "user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.barplot(x='count', y='user_id', data=user_id, color=\"turquoise\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple customers leave reviews for restaurants more than one times. It is valuable for the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = pd.DataFrame(df.user_name.value_counts().head(10))\n",
    "user_name.reset_index(level=0, inplace = True)\n",
    "user_name.columns = ['user_name', 'count']\n",
    "user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.barplot(x='count', y='user_name', data=user_name, color=\"green\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = pd.DataFrame(df.user_name.value_counts().tail(10))\n",
    "user_name.reset_index(level=0, inplace = True)\n",
    "user_name.columns = ['user_name', 'count']\n",
    "user_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since different customers might have same name, in order to invoid error, I will not use user_id in the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.user_rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to convert the string into integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.user_rating = df.user_rating.replace({'5.0 star rating':5,\n",
    "                                         '4.0 star rating':4, \n",
    "                                         '3.0 star rating':3,\n",
    "                                         '2.0 star rating':2,\n",
    "                                         '1.0 star rating':1\n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.DataFrame(df.user_rating.value_counts().head())\n",
    "rating.reset_index(level=0, inplace = True)\n",
    "rating.columns=['rating', 'count']\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.user_rating, color = 'tomato')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- restaurant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.restaurant_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_name = df.groupby(df['restaurant_name']).user_id.count()\n",
    "restaurant_name = pd.DataFrame(restaurant_name)\n",
    "restaurant_name = restaurant_name.reset_index()\n",
    "restaurant_name = restaurant_name.rename(index=str, columns={\"user_id\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = restaurant_name.sort_values(by=['count'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.barplot(x='count', y='restaurant_name', data=top_10, color=\"violet\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_name.sort_values(by=['count']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- restaurant_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.restaurant_rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.restaurant_rating = df.restaurant_rating.replace({'5.0 star rating':5,\n",
    "                                                     '4.5 star rating':4.5,\n",
    "                                                     \n",
    "                                                     '4.0 star rating':4,\n",
    "                                                     '3.5 star rating':3.5,\n",
    "                                                     '3.0 star rating':3,\n",
    "                                                     '2.5 star rating':2.5,\n",
    "                                                     '2.0 star rating':2,\n",
    "                                                     '1.5 star rating':1.5,\n",
    "                                                     '1.0 star rating':1\n",
    "                                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- restaurant_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.restaurant_price.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.restaurant_price = df.restaurant_price.replace({'$':1,\n",
    "                                                     '$$':2, \n",
    "                                                     '$$$':3,\n",
    "                                                     '$$$$':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- restaurant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in range(len(df)):\n",
    "    item = df.restaurant_type.loc[i].replace(',', '')\n",
    "    item = item.replace('&', '')\n",
    "    item = item.replace('(','')\n",
    "    item = item.replace(')','')\n",
    "    item = item.lower()\n",
    "    item = ' '.join(list(set(item.split())))\n",
    "    li.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['restaurant_type'] = li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data cleaning finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.restaurant_type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Hoboken_restaurants_reviews_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hoboken_restaurants_reviews_cleaned.csv')\n",
    "train_raw = df[['user_id','restaurant_name', 'user_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df = pd.DataFrame(train_raw.groupby(['user_id', 'restaurant_name']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df = gb_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gb_df.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_df.to_csv('groupby_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = gb_df.pivot(index = 'user_id', columns ='restaurant_name', values = 'user_rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('recommendation_dataset.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Basic Methods:\n",
    "- co-occurrence matrices\n",
    "- collaborative filtering\n",
    "- matrix decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 co-occurrence Matrices\n",
    "\n",
    "- Background:\n",
    "This is the simpliest method I use to build the recommendation system.   \n",
    "The underlying assumption is that the customers will be interested in the restaurants that the other customers who attended same restaurants with this customer have been.\n",
    "\n",
    "- Algorithms/equations:  \n",
    "    - Co-occurrence Matrix = T(A) * A  \n",
    "    - recommender = Co-occurrence Matrix * u\n",
    "\n",
    "- Advantages:\n",
    "    - Simple\n",
    "    - Build with dataset in any size\n",
    "\n",
    "- Limitations:\n",
    "    - only based on the past behavior\n",
    "    - ignore the user's rating for restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recommendation_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_co_occurence(df):\n",
    "    #replace the rating with 1\n",
    "    df = df.replace({5:1, 4:1, 3:1, 2:1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurence_dataset = get_dataset_co_occurence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2: co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_occurrence_matrices(co_occurence_dataset):\n",
    "    co_matrices =np.matrix(co_occurence_dataset.iloc[:,1:])\n",
    "    co_matrices_t = co_matrices.getT()\n",
    "    co_occurence_matrix = co_matrices_t * co_matrices\n",
    "    np.fill_diagonal(co_occurence_matrix, 0)\n",
    "    return co_occurence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurence_matrix = get_co_occurrence_matrices(co_occurence_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3: recommender for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_occurence_result(co_occurence_dataset,co_occurence_matrix, user_idx=None, user_id = None, top_n=None):\n",
    "    ##input is index\n",
    "    if user_idx is not None:\n",
    "        user = co_occurence_dataset.iloc[user_idx,1:]\n",
    "    ##input is id\n",
    "    if user_id is not None:\n",
    "        user = co_occurence_dataset[co_occurence_dataset.user_id== user_id].iloc[0,1:]\n",
    "    \n",
    "    ##convert Series to array\n",
    "    user_vector = np.array(user)\n",
    "    \n",
    "    ##get co occurence recommender\n",
    "    recommender =  user_vector * co_occurence_matrix\n",
    "    #matrix to array\n",
    "    recommender = np.array(recommender).reshape(-1,)\n",
    "    #array to list\n",
    "    recommender = recommender.tolist()\n",
    "    \n",
    "    ##export the result list for one user\n",
    "    #create result dataframe \n",
    "    user_result = pd.DataFrame(user)\n",
    "    #append recommender list to this result dataframe\n",
    "    user_result['recommender'] = recommender\n",
    "    \n",
    "    #check if the user have already attended this restaurant\n",
    "    #only rank the restaurant they did not attend\n",
    "    result_for_user = user_result[user_result.iloc[:, 0] != 1].sort_values(by = 'recommender', ascending = False)\n",
    "    \n",
    "    #create recommendation list with n recommendations for each user\n",
    "    result_for_user = list(result_for_user.head(top_n).index.values)\n",
    "    return result_for_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_result(co_occurence_dataset, co_occurence_matrix):\n",
    "    # use for loop to get each user's recommendation list in the dataset\n",
    "    recommendation_li = []\n",
    "    for i in range(len(co_occurence_dataset)):\n",
    "        recommendation_for_user = get_co_occurence_result(co_occurence_dataset, co_occurence_matrix, user_id=co_occurence_dataset.user_id[i], top_n=3)\n",
    "        recommendation_li.append(recommendation_for_user)\n",
    "        \n",
    "    print('get list!')\n",
    "    # create export dataset\n",
    "    df = pd.read_csv('recommendation_dataset.csv')\n",
    "    # first column\n",
    "    df = pd.DataFrame(df.user_id)\n",
    "    # second column\n",
    "    df['recommendation'] = recommendation_li\n",
    "    # save\n",
    "    df.to_csv('co_occurence_result.csv')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#store_result(co_occurence_dataset, co_occurence_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 Collaborative Filtering\n",
    "- Background: My second recommendation system use collaborative filtering. This method is tring to find people with similar interests, analyze those guys behaviors, and recommend user the same items. These are two basic approaches in Collaborative Filtering: user-based collaborative filtering and item-based collaborative filtering.\n",
    "  \n",
    "- Basically, all of those two methods contains two steps:\n",
    "    - First Step: Find out how many users/items in the database are similar to the given user/item.  \n",
    "    - Second Step: Assess other users/items to predict what grade you would give the user of this product, given the total weight of the users/items that are more similar to this one.\n",
    "    \n",
    "\n",
    "- Algorithms/Equations:\n",
    "    - Similarity Calculation: \n",
    "        1. cosine similarity:\n",
    "        ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/a71c4add4abded66efd42b202c76f6a59944a587)\n",
    "        2. Jaccard Similarity: \n",
    "        ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d54c3ac9fb70b8e3d76166589c880fc9df119970)\n",
    "        3. Pearson Similarity:\n",
    "        ![](https://i.stack.imgur.com/KaM0y.gif)\n",
    "    - Recommend_items: simple **weighted arithmetic mean** according to the degree of similarity to fill empty cells in the table.\n",
    "    \n",
    "      \n",
    "- Advantages:\n",
    "    - Take the rating into account  \n",
    "    \n",
    "  \n",
    "- Disadvantages:\n",
    "    - Only focus on the privious behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('groupby_dataset.csv')\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)\n",
    "\n",
    "train_data_gl = graphlab.SFrame(train_data)\n",
    "test_data_gl = graphlab.SFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2: calculate similarity \n",
    "    - Three Similarity\n",
    "        1. cosine similarity; \n",
    "        2. Jaccard Similarity; \n",
    "        3. Pearson Similarity\n",
    "    - Two approches\n",
    "        1. user-item collaborative filtering\n",
    "        2. item-item collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before go forward to collaborative filtering, I might try popularity_recommender\n",
    "    - Arg:\n",
    "        - train_data: the SFrame which contains the required data\n",
    "        - user_id: the column name which represents each user ID\n",
    "        - item_id: the column name which represents each item to be recommended\n",
    "        - target: the column name representing scores/ratings given by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_model = graphlab.popularity_recommender.create(train_data_gl, \n",
    "                                                          user_id='user_id', \n",
    "                                                          item_id='restaurant_name', \n",
    "                                                          target='user_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_recomm = popularity_model.recommend(users=range(1,6),k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_recomm.print_rows(num_rows=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the results are same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby(by='restaurant_name')['user_rating'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since all the recommended restaurant have an average rating of 5. So the popularity recommender is not accurate enough. So I will come back to collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine_model = graphlab.item_similarity_recommender.create(train_data_gl, user_id='user_id', \n",
    "                                                             item_id='restaurant_name', \n",
    "                                                             target='user_rating', \n",
    "                                                             similarity_type='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jaccard_model = graphlab.item_similarity_recommender.create(train_data_gl, user_id='user_id', \n",
    "                                                             item_id='restaurant_name', \n",
    "                                                             target='user_rating', \n",
    "                                                             similarity_type='jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pearson Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pearson_model = graphlab.item_similarity_recommender.create(train_data_gl, user_id='user_id', \n",
    "                                                             item_id='restaurant_name', \n",
    "                                                             target='user_rating', \n",
    "                                                             similarity_type='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3: Predict the rating and recommend top 3 rating restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine_recommendation = Cosine_model.recommend(k=3,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine_recommendation.save('Cosine_recommendation_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jaccard_recommendation = Jaccard_model.recommend(k=3,verbose=False)\n",
    "Jaccard_recommendation.print_rows(num_rows=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pearson_recommendation = Pearson_model.recommend(k=3,verbose=False)\n",
    "Pearson_recommendation.print_rows(num_rows=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 4: Accuracy Evaluation\n",
    "Recall:What ratio of items that a user likes were actually recommended.\n",
    "\n",
    "Precision:Out of all the recommended items, how many the user actually liked?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = graphlab.compare(test_data_gl, [popularity_model, Cosine_model, Jaccard_model, Pearson_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "\n",
    "The cosine and jaccard model perform better than the others for this dataset. And cosine model is slightly better than jaccard model. So I will use cosine model to build the second recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3 Matrix Factorization via Singular Value Decomposition\n",
    "- Background: The Matrix Factorization is the third method I used to build recommendation system. The assumption of matrix factorization is that each user have tendency to like different features of item. For example, in Hoboken restaurant dataset, the features might be theme and style of the restaurant, environment, service quality, food quality of restaurants and so on. Different user have different expectation and preferences for different features. In addition, each item, restaurant in this case, have features in different degree. We assume that the user will rate higher to a new restaurant with more features this user like and will rate lower to a new restaurant with less features this user like. \n",
    "\n",
    "- Algorithms/equation:\n",
    "    - Basic Algorithm:\n",
    "     ![](https://raw.githubusercontent.com/houlaizhexq/images/master/%E9%A2%84%E6%B5%8B%E5%BE%97%E5%88%86.jpg)\n",
    "     ![](https://www.packtpub.com/sites/default/files/Article-Images/B01900_4.png)\n",
    "            - Rui: user u's rating for item i\n",
    "            - Qi:item i's similarity with a feature k\n",
    "            - Pu:user u's preference for a feature k \n",
    "    - Algorithm with bias:\n",
    "    ![](https://raw.githubusercontent.com/houlaizhexq/images/6ebc5f5aa3b6a31dfcb6091fbb16cf7e81a2ed8c/%E5%B8%A6%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3%E7%9A%84%E9%A2%84%E6%B5%8B.jpg)\n",
    "    - Algorithm with historical feedback:\n",
    "    ![](https://raw.githubusercontent.com/houlaizhexq/images/6ebc5f5aa3b6a31dfcb6091fbb16cf7e81a2ed8c/%E5%B8%A6%E6%9C%89%E5%8E%86%E5%8F%B2%E5%92%8C%E6%A0%87%E7%AD%BE%E7%9A%84%E8%AF%AF%E5%B7%AE.jpg)\n",
    "    - Algorithm with change by time:\n",
    "    ![](https://raw.githubusercontent.com/houlaizhexq/images/6ebc5f5aa3b6a31dfcb6091fbb16cf7e81a2ed8c/%E5%8A%A0%E5%85%A5%E6%97%B6%E9%97%B4%E5%9B%A0%E7%B4%A0%E5%90%8E%E7%9A%84%E4%BC%B0%E8%AE%A1%E8%AF%84%E5%88%86.jpg)\n",
    "    \n",
    "\n",
    "- Advantages:\n",
    "    - Masive dataset\n",
    "    - easy to add new parameter(bias, historical feedback, time changes and so on)\n",
    "\n",
    "- Disadvantages:\n",
    "    - Computation resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Data Preparationg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('recommendation_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices =np.matrix(train_set.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2: Extract features k  \n",
    "    I could simply extract features k with user_id, restaurant_name, rating or try more complicative method incorporating NLP. \n",
    "    - Rating only\n",
    "    - Reveiw text based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Only\n",
    "reduce the dimension of original matrices and got two new matrices.\n",
    "- new matrix 1: represent user i's preference of different features k\n",
    "- new matrix 2: represent the item j's similarity to features k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = NMF(n_components=5, init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = k_model.fit_transform(matrices)\n",
    "H = k_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3: Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nR = np.matrix(np.dot(W,H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns = train_set.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.insert(0, 'user_id', train_set.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 4: Export the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_top_3 = list(result_df.iloc[3,1:].sort_values(ascending=False).head(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_top_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_li = []\n",
    "for i in range(len(result_df)):\n",
    "    attended_res_li = None\n",
    "    try:\n",
    "        attended_res_li = list(train_set.iloc[i,1:][train_set.iloc[i,1:] != 0].index)\n",
    "    except:\n",
    "        pass\n",
    "    if attended_res_li is not None:\n",
    "        for res in attended_res_li:\n",
    "            result_df.loc[i, res] = 0\n",
    "\n",
    "    recommendation_top_3 = list(result_df.iloc[i,1:].sort_values(ascending=False).head(3).index)\n",
    "    recommendation_li.append(recommendation_top_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_li[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.DataFrame(train_set.user_id)\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df['Recommendation'] = recommendation_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.to_csv('matrix_factorization_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Deep Learning Methods:\n",
    "I have already build three recommendation systems with popular recommendation algorithms. Now, I will try to use Neural Networks to build a advanced recommendation systems\n",
    "\n",
    "Objective: Top 3 scores restaurants recommendation\n",
    "\n",
    "Output:\n",
    "    - estimated rating for each of 302 restaurants\n",
    "Independent variables:\n",
    "    - user_rating\n",
    "    - restaurant rating\n",
    "    - restaurant price\n",
    "    - restaurant type\n",
    "    - reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hoboken_restaurants_reviews_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df = df[['user_id','restaurant_name','user_rating','restaurant_rating','restaurant_price','restaurant_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df = nn_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_variable(nn_df,variable_names):\n",
    "    variables_li = []\n",
    "    for variable in variable_names:\n",
    "        variables_li.append(nn_df[variable])\n",
    "    encoder = Normalizer()\n",
    "    to_array = np.asarray(variables_li)\n",
    "    norm_result = encoder.fit_transform(to_array)\n",
    "    norm_result = norm_result.T\n",
    "    return norm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP- tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "tokenizer = RegexpTokenizer(\"[a-z']+\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [stemmer.stem(t) for t in tokens] \n",
    "\n",
    "def get_tf(data, idf, max_df=1.0, min_df=1, ngram_range=(1,1)):\n",
    "    if idf:\n",
    "        \"\"\"Convert a collection of raw documents to a matrix of TF-IDF features.\"\"\"\n",
    "        m = TfidfVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram_range, tokenizer=tokenize,lowercase=True)\n",
    "    d = m.fit_transform(data)\n",
    "    return m, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_df(nn_df, norm_result, tfidf_d, variable_names):\n",
    "    norm_result = pd.DataFrame(norm_result)\n",
    "    tfidf_d = pd.DataFrame(tfidf_d.toarray())\n",
    "    for index, name in enumerate(variable_names):\n",
    "        tfidf_d[name] = norm_result.iloc[:,index]\n",
    "    tfidf_d.index = nn_df.user_id\n",
    "    tfidf_d['output'] = list(nn_df.restaurant_name)\n",
    "    return tfidf_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning - NN\n",
    "    - NN  @ sklearn\n",
    "    - NN @ tensorflow\n",
    "\n",
    "Input:\n",
    " - Customer's attended restaurants's tag\n",
    "\n",
    "Output:\n",
    " - probability of the restaurants they will be interested with similary tag.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_df(model, X_test):\n",
    "    probability = model.predict_proba(X_test)\n",
    "    recommendation_df = pd.DataFrame({'restaurant_name':model.classes_,'probability':probability[0]})\n",
    "    return recommendation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(top_n, y_test,recommendation_df):\n",
    "    top_n = recommendation_df[recommendation_df.restaurant_name != y_test].sort_values(by='probability', ascending=False).head(top_n)\n",
    "    recommendation_li = []\n",
    "    for i in range(len(top_n)):\n",
    "        recommendation_item = list(top_n.iloc[i,:])\n",
    "        recommendation_li.append(recommendation_item)\n",
    "    output = str(recommendation_li).replace('[','')\n",
    "    output = output.replace(']','')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = ['user_rating', 'restaurant_rating', 'restaurant_price']\n",
    "\n",
    "norm_result = normalize_variable(nn_df,variable_names)\n",
    "\n",
    "tfidf_m, tfidf_d = get_tf(nn_df['restaurant_type'], idf=True, max_df=0.5, min_df=10)\n",
    "\n",
    "df = get_nn_df(nn_df, norm_result, tfidf_d, variable_names)\n",
    "\n",
    "X_train = df.iloc[:,:-1]\n",
    "y_train = df.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('normalized_neural_network_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn= MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(16, 3), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nn = nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 3\n",
    "X_test = np.asarray(X_train.iloc[2150,:])\n",
    "X_test = X_test.reshape(-1,1).T\n",
    "y_test = y_train.iloc[2150]\n",
    "recommendation_df = get_recommendation_df(nn, X_test)\n",
    "output = get_output(top_n,y_test,recommendation_df)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.DataFrame(nn_df.user_id)\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_the_recommendation(X_train, y_train,nn_df, top_n, nn):\n",
    "    export_df = pd.DataFrame(nn_df.user_id)\n",
    "    recommendation_li = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_test = np.asarray(X_train.iloc[i, :])\n",
    "        X_test = X_test.reshape(-1, 1).T\n",
    "        y_test = y_train.iloc[i]\n",
    "        recommendation_df = get_recommendation_df(nn, X_test)\n",
    "        output = get_output(top_n, y_test, recommendation_df)\n",
    "        recommendation_li.append(output)\n",
    "    export_df['Recommendation'] = recommendation_li\n",
    "    export_df.to_csv('Neural_Network_result.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_the_recommendation(X_train, y_train ,nn_df, top_n, nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Neural_Network_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Neural_Network_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation the Recommendation System\n",
    "There are multiple elements to evaluate and elevate the performance of recommendation system. However, I could only test the accuracy with the limitation of this project.\n",
    "\n",
    "- Customer Satisfaction: click possibility, duration time, Conversion rate\n",
    "\n",
    "- accuracy: MSE, Return rate, accuracy\n",
    "\n",
    "- covering rate: cross entropy, Gini Coefficient\n",
    "\n",
    "- diversity: features similarity\n",
    "\n",
    "- creative/innovative: new items, the itmes did not puchase\n",
    "\n",
    "- surprice: at first glance, it seems irrelevant, but provide user surprice in a positive way.\n",
    "\n",
    "- confidence: interactive\n",
    "\n",
    "- real time updated and cold start\n",
    "\n",
    "- fraud detection\n",
    "\n",
    "- profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
