{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A function to open home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import random\n",
    "import time\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_website(URL='https://www.yelp.com/'):\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "    driver.get(URL)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A function to type hoboken(zipcode 07030) + restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_location_business(driver, location_input = '07030', business_type = 'Restaurant'):\n",
    "    normal_delay = random.normalvariate(2, 0.5)\n",
    "    time.sleep(normal_delay)\n",
    "    \n",
    "    active_location_search_input = driver.find_element_by_id(\"dropperText_Mast\")\n",
    "    active_location_search_input.clear()\n",
    "    active_location_search_input.send_keys(location_input)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    active_business_search_input = wait.until(EC.element_to_be_clickable((By.ID, \"find_desc\")))\n",
    "    active_business_search_input.send_keys(business_type)\n",
    "    hit_search = driver.find_element_by_id(\"header-search-submit\")\n",
    "    search_result = hit_search.click()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data\n",
    "\n",
    "we require:\n",
    "1. restaurant name(Grand Vin)\n",
    "2. restaurant id \n",
    "3. restaurant general star range (4.0)\n",
    "4. restaurant price range ($$)\n",
    "5. restaurant category list (Wine Bars, Italian, Cocktail)\n",
    "6. each review under a restaurant  \n",
    "    - user name (Jason L.)\n",
    "    - user id (\"/user_details?userid=K58UsGqR6k5lhPZKCVcuRg\")\n",
    "    - review text (...)\n",
    "    - rating (5.0 star rating)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- collect_res_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_df(driver):\n",
    "    ad_no  = detect_ad_no(driver)\n",
    "    restaurant_id_xpath_li = [] \n",
    "    restaurant_id_li = []\n",
    "    restaurant_name_li = []\n",
    "    for i in range(10):\n",
    "        no = str(i+1+ad_no)\n",
    "        id_xpath = \"\"\"//*[@id=\"super-container\"]/div/div[2]/div[1]/div/div[5]/ul[2]/li[{}]/div/div[1]/div[1]/div/div[2]/h3/span\"\"\"\n",
    "        id_xpath = id_xpath.format(no)\n",
    "        restaurant_id_xpath_li.append(id_xpath)\n",
    "    for i in range(len(restaurant_id_xpath_li)):\n",
    "        restaurant_id_element = driver.find_element_by_xpath(restaurant_id_xpath_li[i])\n",
    "        data_html = restaurant_id_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "        restaurant_id_tag = soup.find('a').attrs\n",
    "        restaurant_id = restaurant_id_tag['data-hovercard-id']\n",
    "        restaurant_id_li.append(restaurant_id)\n",
    "\n",
    "        restaurant_name = soup.find('a').text\n",
    "        restaurant_name_li.append(restaurant_name)\n",
    "    df = pd.DataFrame(data = {'restaurant_id' : restaurant_id_li, 'restaurant_name':restaurant_name_li})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_id():\n",
    "    driver = open_website('https://www.yelp.com/')\n",
    "    driver = select_location_business(driver, '07030', 'Restaurant')\n",
    "    id_df = extract_id_df(driver)\n",
    "    for i in range(35):\n",
    "        next_button = driver.find_element_by_link_text(\"\"\"Next\"\"\")\n",
    "        next_button.click()\n",
    "        \n",
    "        id_df_more = extract_id_df(driver)\n",
    "        \n",
    "        id_df = pd.concat([id_df, id_df_more], axis=0, names=None, ignore_index = True)\n",
    "        normal_delay = random.normalvariate(2, 0.5)\n",
    "        time.sleep(normal_delay)\n",
    "    \n",
    "    id_df.to_csv(\"restaurant_id.csv\")\n",
    "    return id_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- collect res profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_restaurant_li(driver):\n",
    "    global restaurant_header_element, soup\n",
    "    restaurant_header_element = None\n",
    "    try:\n",
    "        restaurant_header_element = driver.find_element_by_class_name(\"\"\"biz-page-header\"\"\")\n",
    "        data_html = restaurant_header_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "    except:\n",
    "        print('Error:detect header.')\n",
    "        pass\n",
    "    #res_name\n",
    "\n",
    "    restaurant_name_element = soup.find('h1', attrs={'class':\"biz-page-title\"})\n",
    "    restaurant_name = restaurant_name_element.text.split()\n",
    "    restaurant_name = ' '.join(restaurant_name)\n",
    "    \n",
    "    try:\n",
    "        #res_rating\n",
    "        restaurant_header_element = driver.find_element_by_class_name(\"\"\"biz-page-header\"\"\")\n",
    "        data_html = restaurant_header_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "        restaurant_rating_tag = soup.find('div', attrs={'class':\"i-stars\"}).attrs\n",
    "        restaurant_rating = restaurant_rating_tag['title']\n",
    "    except:\n",
    "        restaurant_rating = None\n",
    "        \n",
    "    try:\n",
    "        #res_price\n",
    "        restaurant_header_element = driver.find_element_by_class_name(\"\"\"biz-page-header\"\"\")\n",
    "        data_html = restaurant_header_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "        restaurant_price_element = soup.find('span',attrs={'class':\"business-attribute\"})\n",
    "        restaurant_price = restaurant_price_element.text\n",
    "    except:\n",
    "        restaurant_price = None\n",
    "\n",
    "    try:\n",
    "        #res_tag\n",
    "        restaurant_header_element = driver.find_element_by_class_name(\"\"\"biz-page-header\"\"\")\n",
    "        data_html = restaurant_header_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "        restaurant_tag_element = soup.find('span', attrs = {'class':\"category-str-list\"})\n",
    "        restaurant_tag = restaurant_tag_element.text.split()\n",
    "        restaurant_tag = ', '.join(restaurant_tag)\n",
    "    except:\n",
    "        restaurant_tag = None\n",
    "\n",
    "    li = [restaurant_name, restaurant_rating,restaurant_price,restaurant_tag]\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- collect user reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews_df(driver):\n",
    "    name_li = []\n",
    "    rating_li = []\n",
    "    text_li = []\n",
    "    user_id_li = []\n",
    "\n",
    "    reviews_table_element = driver.find_element_by_class_name(\"review-list\")\n",
    "    data_html = reviews_table_element.get_attribute('innerHTML')\n",
    "    soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "    reviews_table = soup.find('ul')\n",
    "    \n",
    "    #user_name\n",
    "    name_tag = reviews_table.find_all('a', attrs = {'class':'user-display-name js-analytics-click'})\n",
    "    for i in range(len(name_tag)):\n",
    "        name = name_tag[i].text\n",
    "        name_li.append(name)\n",
    "    \n",
    "    #user_id\n",
    "    for i in range(len(name_tag)):\n",
    "        user_id = name_tag[i].attrs['data-hovercard-id']\n",
    "        user_id_li.append(user_id)\n",
    "\n",
    "    #user_rating\n",
    "    reviews_tag = reviews_table.find_all('div',attrs= {\"class\":'review-content'})\n",
    "    for i in range(len(reviews_tag)):\n",
    "        review_rating_tag = reviews_tag[i].find('div',attrs={'class':'i-stars'}).attrs\n",
    "        review_rating = review_rating_tag['title']\n",
    "        rating_li.append(review_rating)\n",
    "    #user_text\n",
    "    for i in range(len(reviews_tag)):\n",
    "        review_text_tag = reviews_tag[i].find('p')\n",
    "        review_text = review_text_tag.text\n",
    "        text_li.append(review_text)\n",
    "    \n",
    "    df = pd.DataFrame(data = {'user_name': name_li, 'user_id':user_id_li,'user_rating':rating_li,'user_text':text_li})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select restaurant\n",
    "- select each re at one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ad_no(driver):\n",
    "    try:\n",
    "        data_element = driver.find_element_by_xpath(\"\"\"//*[@id=\"super-container\"]/div/div[2]/div[1]/div/div[5]/ul[2]\"\"\")\n",
    "        data_html = data_element.get_attribute('innerHTML')\n",
    "        soup = bs4.BeautifulSoup(data_html,'html5lib')\n",
    "        ad_list = soup.find_all('li', attrs={'class': 'js-yloca js-yloca-search yloca-search-result', \"data-ad-placement\":\"above_search\"})\n",
    "        ad_no = len(ad_list)\n",
    "    except:\n",
    "        ad_no = 0\n",
    "    return ad_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_business_extract(driver):\n",
    "    res_li = []\n",
    "    res_li = extract_restaurant_li(driver) \n",
    "    reviews_df = None\n",
    "    reviews_df = extract_reviews_df(driver)\n",
    "    count = 1\n",
    "    for i in range(48):\n",
    "        try:\n",
    "            next_button = driver.find_element_by_link_text(\"\"\"Next\"\"\")\n",
    "            next_button.click()\n",
    "            reviews_df_more = extract_reviews_df(driver)\n",
    "            reviews_df = pd.concat([reviews_df, reviews_df_more], axis=0, names=None, ignore_index = True)\n",
    "            normal_delay = random.normalvariate(2, 0.5)\n",
    "            time.sleep(normal_delay)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    reviews_df['restaurant_name'] = res_li[0]\n",
    "    reviews_df['restaurant_rating'] = res_li[1]\n",
    "    reviews_df['restaurant_price'] = res_li[2]\n",
    "    reviews_df['restaurant_type'] = res_li[3]\n",
    "    file_name = str(res_li[0])+('.csv')\n",
    "    df = reviews_df\n",
    "    df.to_csv(file_name)\n",
    "    if count == 49:\n",
    "        if res_li[0] not in error_li:\n",
    "            error_li.append(res_li[0])\n",
    "            print('Pages out of range {}'.format(res_li[0]))\n",
    "    back_page_no = \"window.history.go({})\".format(str(-count))\n",
    "    driver.execute_script(back_page_no)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_back_all_re(driver):\n",
    "    global reviews_df, count, error_li, ad_no, res_li\n",
    "    \n",
    "    restaurant_xpath_li = []\n",
    "    for i in range(50):\n",
    "        for i in range(10):\n",
    "            ad_no = None\n",
    "            ad_no = detect_ad_no(driver)\n",
    "            no = str(i+1+ad_no)\n",
    "            re_xpath = \"\"\"//*[@id=\"super-container\"]/div/div[2]/div[1]/div/div[5]/ul[2]/li[{}]/div/div[1]/div[1]/div/div[2]/h3/span/a\"\"\"\n",
    "            re_xpath = re_xpath.format(no)\n",
    "            restaurant_xpath_li.append(re_xpath)\n",
    "\n",
    "        for i in range(len(restaurant_xpath_li)):\n",
    "            res_li = None\n",
    "            reviews_df = None\n",
    "            select_business = driver.find_element_by_xpath(restaurant_xpath_li[i])\n",
    "            click_business = select_business.click()\n",
    "            \n",
    "            normal_delay = random.normalvariate(5, 0.5)\n",
    "            time.sleep(normal_delay)\n",
    "            driver = one_business_extract(driver)\n",
    "            \n",
    "        next_button = driver.find_element_by_link_text(\"\"\"Next\"\"\")\n",
    "        next_button.click()\n",
    "    driver.close()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_error(error_li):\n",
    "    global reviews_df, res_li\n",
    "    for error_restaurant in error_li:\n",
    "        driver = open_website('https://www.yelp.com/')\n",
    "        res_li = []\n",
    "        driver = select_location_business(driver, '07030', error_restaurant)\n",
    "        ad_no = detect_ad_no(driver)\n",
    "        no = str(1+ad_no)\n",
    "        re_xpath = \"\"\"//*[@id=\"super-container\"]/div/div[2]/div[1]/div/div[5]/ul[2]/li[{}]/div/div[1]/div[1]/div/div[2]/h3/span/a\"\"\"\n",
    "        re_xpath = re_xpath.format(no)\n",
    "        normal_delay = random.normalvariate(2, 0.5)\n",
    "        time.sleep(normal_delay)\n",
    "        select_business = driver.find_element_by_xpath(re_xpath)\n",
    "        select_business.click()\n",
    "        \n",
    "        res_li = extract_restaurant_li(driver)\n",
    "        reviews_df = None\n",
    "        reviews_df = extract_reviews_df(driver)\n",
    "        count = 1\n",
    "        for i in range(222):\n",
    "            try:\n",
    "                next_button = driver.find_element_by_link_text(\"\"\"Next\"\"\")\n",
    "                next_button.click()\n",
    "                reviews_df_more = extract_reviews_df(driver)\n",
    "                reviews_df = pd.concat([reviews_df, reviews_df_more], axis=0, names=None, ignore_index = True)\n",
    "                normal_delay = random.normalvariate(2, 0.5)\n",
    "                time.sleep(normal_delay)\n",
    "                count += 1\n",
    "            except:\n",
    "                pass\n",
    "        res_li = extract_restaurant_li(driver)\n",
    "        reviews_df['restaurant_name'] = res_li[0]\n",
    "        reviews_df['restaurant_rating'] = res_li[1]\n",
    "        reviews_df['restaurant_price'] = res_li[2]\n",
    "        reviews_df['restaurant_type'] = res_li[3]\n",
    "        file_name = str(res_li[0])+('.csv')\n",
    "        df = reviews_df\n",
    "        df.to_csv(file_name)\n",
    "        normal_delay = random.normalvariate(2, 0.5)\n",
    "        time.sleep(normal_delay)\n",
    "        driver.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataset():\n",
    "    path = \"/Users/mani/Desktop/Dropbox/001 - Campus courses/BIA 660 - Web Analytics/Final Project/BIA660D_Group_1_Project/data_gathering\"\n",
    "    files= os.listdir(path)\n",
    "    df = pd.read_csv(\"Grand Vin.csv\")\n",
    "    for file in files:\n",
    "        if file.endswith('csv') and file != \"restaurant_id.csv\" and file != \"Grand Vin.csv\":\n",
    "            df_new = pd.read_csv(file)\n",
    "            df = pd.concat([df, df_new], axis=0, names=None, ignore_index = True)\n",
    "    df.to_csv('Hoboken_restaurants_reviews.csv')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    driver = open_website('https://www.yelp.com/')\n",
    "    driver = select_location_business(driver, '07030', 'Restaurant')\n",
    "    driver = select_back_all_re(driver)\n",
    "    fix_error(error_li)\n",
    "    concat_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
